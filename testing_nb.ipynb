{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/emoji_table.txt', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoji_dict = df['count'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòÄ\n"
     ]
    }
   ],
   "source": [
    "print df.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üáÆüá®\n"
     ]
    }
   ],
   "source": [
    "for key in emoji_dict.keys():\n",
    "    print key\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚õπ\n"
     ]
    }
   ],
   "source": [
    " print  u'\\u26f9'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets_data_path = 'data/twitter_dump_small.txt'\n",
    "\n",
    "tweets_data = []\n",
    "\n",
    "# parse tweets into json and store it in list\n",
    "tweets_file = open(tweets_data_path, \"r\")\n",
    "for line in tweets_file:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "        tweets_data.append(tweet)\n",
    "    except:\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 10-13: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-65dd71fc75e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 10-13: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "print len(xx.split()[-1])\n",
    "\n",
    "str(xx.split()[-1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = xx.replace(u'\\U0001f60a', u' \\U0001f60a ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"I've\",\n",
       " u'enjoyed',\n",
       " u'this',\n",
       " u'basketball',\n",
       " u'season',\n",
       " u'though....the',\n",
       " u'journey',\n",
       " u'was',\n",
       " u'sooo',\n",
       " u'fun',\n",
       " u'and',\n",
       " u'exciting',\n",
       " u'while',\n",
       " u'it',\n",
       " u'lasted....',\n",
       " u'\\U0001f60a',\n",
       " u'\\U0001f60a',\n",
       " u'\\U0001f49c\\U0001f49b']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx = tweets_data[13]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @1047KDUK: May you have as much fun with your weekend as Chris Martin and Blue Ivy are in these superbowl backstage pics https://t.co/fk‚Ä¶\n",
      "RT @SUPERELFS06: Preview/160305 LeeTeuk, Kangin &amp; HeeChul having fun at ICN ^^~  going to Shanghai ¬©orianejewel https://t.co/EBeIheowXx\n",
      "@Ronnie2K @LD2K your game is so shit I literally took it out mid game &amp; threw it out in the other room. actually had fun a couple days wtf\n",
      "RT @ShanSossamon: I miss all involved with this special movie &lt;3 https://t.co/VX1RLFITa1\n",
      "RT @TheObamaDiary: Fun Fact: In Clinton v Dole 96 presidential election, guess who Cenk Uygur voted for (he was 26)?\n",
      "\n",
      "Yep, Dole\n",
      "\n",
      "His Clinto‚Ä¶\n",
      "Having fun playing #CSRRacing for iOS, why not join me for FREE?\n",
      "https://t.co/PYVqtAKcxA\n",
      "RT @j15hooper: I wish I was a little kid again. No worries. No problems. No drama. No responsibility. Just playing and having fun.\n",
      "Photo - Fridays spent with friends are always fun, especially when Pudge is in town! #TexasRangers https://t.co/ULQx8nm2wP\n",
      "@DayAlabaster @Slate its all part of twitter fun #clintonmustgo\n",
      "https://t.co/ddIOlGP5CI https://t.co/1FPLncO2cY https://t.co/TNmZnZPLnu ...\n",
      "@RollingStone \n",
      "Cjclxucsy accused of a mineral water and friends and family members who are you guys doing anything fun with your gift\n",
      "@SubmissiveLexi your going to have Fun with that, when you get to use it.\n",
      "thank you shaniaaa https://t.co/zmMutSFgR8\n",
      "I've enjoyed this basketball season though....the journey was sooo fun and exciting while it lasted....üòäüòäüíúüíõ\n",
      "I got my liptifulinternational in today. I'm having so much fun playing with this thing. #plump‚Ä¶ https://t.co/iKzNga49ve\n",
      "my idea of a fun Friday night is rearranging the kitchen cabinets with @Fricke1947.  üòò\n",
      "RT @JonahMarais: .@wydmarais_ that'd actually be so fun üòÅü§òüèª\n",
      "This is definitely gonna be fun\n",
      "Twitter is only fun when @benshapiro and @Nero go at each other's throats.\n",
      "RT @VerucaJames: RT @AmarnaMiller: Having fun with @verucajames #BJ &amp;lt;3 https://t.co/6boXDK1Lkr\n",
      "RT @nicklamuro: @bphogan Yeah, that is a fun one from the world of OSX. They changed things so that native extensions compiling with warns ‚Ä¶\n",
      "RT @MarriedAffairUK: Find a #sexual connection for discreet fun at...\n",
      "\n",
      "https://t.co/aPD2rvuFn4\n",
      "\n",
      "#sexualencounters #lprtg\n",
      "Teen has a group fucking fun. Alt hotKtie teenager #nudeCam #deepthroat #nudity https://t.co/APMbJbgomV https://t.co/ZFHzKJt1r4\n",
      "RT @IDareYouBamber: My grandma is having too much fun üòÇ https://t.co/YCGP0k1aj0\n",
      "RT @dabmandan: don't date someone if you can't have fun at the grocery store with them\n",
      "RT @vibranthome: Fun Easter project for the children https://t.co/nKuibUdYnB\n",
      "Had some fun today with some blue üòçüëåüèº‚ö´Ô∏èüîµ https://t.co/Bo8bQSvPJU\n",
      "Spiderman &amp; Frozen Elsa vs Evil Queen! Elsa Gets a Gummy Joker Tongue! Superhero Fun in Real Life :)lll https://t.co/67seCbZQT8\n",
      "RT @SteveDeaceShow: Had a really fun interview with an atheist conservative today at #CPAC2016. I'll definitely share the video when it com‚Ä¶\n",
      "@Machu_ree @awlilnatty peeling is half the fun brother. Really lets you get to know the orange. Every orange has a personality\n",
      "RT @TheDukeNation: Did a fun Q&amp;A with Duke's newest commit, @5jackwhite! Will be releasing it tomorrow morning!\n",
      "\n",
      "P.S. #DukeNation is going ‚Ä¶\n",
      "RT @yoonminist: i hope yasmin, sabrina, fia, and my other indo mutuals have fun today!!!!!\n",
      "nope you‚Äôre not RT @saimaloveee: am I the only one that doesn‚Äôt find hookah fun\n",
      "ppl need to stop using the word \"savage\" as an excuse to be rude and make fun of others. smh https://t.co/5fzPYB8Orp\n",
      "RT @xrzes: Being a vegetarian so fun I just got three bags of broccoli https://t.co/u5XbYNjste\n",
      "RT @Kansas_SOE: The @children Game On! participants, staff, and #KU visitors pose for a fun picture in Guatemala. https://t.co/RpQGWw6CJH\n",
      "RT @lala: Ladies of POWER @naturi4real @misslloren such a fun evening #powertv #comingsoon https://t.co/4nWgBhfD1o\n",
      "@miltonmustangs @MDHighSchool  https://t.co/NyDLroskU3\n",
      "RT @Taefresh_: When i wanna have fun, i freestyle. Nothing serious. Check out one of my latest freestylesüò§üî• https://t.co/0Tb8tSlnZY\n",
      "I know how it feels to want see the idol, and now you also feel itüòÇüòã Have fun there, iqbaalüíãüíÉ https://t.co/vMv9AkrRiT\n",
      "RT @CoachSBechtel: Fun day at the pit! Proud of #OWUpv for taking 5 out of 8 places at the #NCACITRK16 today #WSAT #ohwooo #OWUTF #inTENsity\n",
      "@judahandthelion better man &amp; take it all back (cos it was so fun to dance to at your concert)\n",
      "RT @natekgarner: bye holidays it was fun!\n",
      "sooo is it summer yet?\n",
      "RT @91sammysam: Yesterdays color party was so much fun üëåüèΩüíó\n",
      "RT @Melissaa_ruiz: Back handsprings are fun!!!\n",
      "RT @SylvieD_xoxo: When you stay home watching everyone's snapchats of the fun they're having https://t.co/51Oa7E3mQ1\n",
      "Freudian slip? Searching Home Depot for a \"Nail Gun\" and I accidentally typed \"Nail Fun\". #girlscanlovepowertoolstoo\n",
      "#JaredLeto Had Fun Interacting with the #SuicideSquad Cast as #TheJoker https://t.co/V0yGcQbAMU\n",
      "RT @snsgroup: Great fun with @NicolaSturgeon this morning as she becomes the the official Patron of the @ScottishFA women's team. https://t‚Ä¶\n",
      "RT @simoncholland: My kid got made fun of at school because the clementine I sent in her lunch wasn't a name brand.\n",
      "moving is always fun üôÉ\n",
      "RT @kd25___: Weed is just fun tobacco  https://t.co/4zZpPCB8QH\n",
      "why all fun\n",
      "The movie is here: https://t.co/gfjyysfoQV\n",
      "Morphed college whores having the best fun ever https://t.co/UcCi0hnMIo\n",
      "RT @TheObamaDiary: Fun Fact: In Clinton v Dole 96 presidential election, guess who Cenk Uygur voted for (he was 26)?\n",
      "\n",
      "Yep, Dole\n",
      "\n",
      "His Clinto‚Ä¶\n",
      "RT @CassidyJonesAdv: \"Fun. Suspenseful. Clean. Fast-paced. I can't recommend this series enough\" 4.8‚òÖ of 400+ rev https://t.co/TqJurz6eVv h‚Ä¶\n",
      "So much fun today w/@GwynethPaltrow learning about her new organic skincare line @goop! Product reviews coming soon https://t.co/VYuEzormgw\n",
      "#Bears News Matt Forte to Pats? Raiders go all-in? Five fun free agent fits (Shutdown Corner) https://t.co/SUwwtTNNdN\n",
      "RT @Neeru_Insaan: @Gurmeetramrahim the real fun in your movie is simply touching the mind and heart sensually. \n",
      "\n",
      "Omg. \n",
      "awesome feeling  #Fa‚Ä¶\n",
      "I'd like to personally thank the girl who was stood behind me at sleeping with sirens; for making fun of my height and then how I speaküòíüñïüèº\n",
      "So that April 16 game should be fun\n",
      "Here is your fun fact of the day! Someone get me a bottle of A1 sauce. https://t.co/pxMW8v9zuz\n",
      "RT @wilson_baxter: Haha glad to know that was the first place you went to! Hope you two have fun üòÇüòÇüòÇüòÇüòÇüòÇüòÇ\n",
      "@SilverhawkARP That sounds like fun. What's London like?\n",
      "RT @MgaPatama: \"I want to refresh my mind, clear all my problems and just have fun with life.\"\n",
      "@ThirstyRando but i don't know why anyone would have purposely bred it that way unless just for fun or possibly silage or something\n",
      "@rnrkd um......fun vacay, looks like\n",
      "RT @TechCrunch: Shots Updates App To Focus On Fun https://t.co/d9x82GQ0k3\n",
      "For real fruity fun in your hand try this app from #Reflex Gaming! https://t.co/1ehcrndj7J https://t.co/zAGilXhZrg\n",
      "RT @MohamedAbbaass: ŸÖÿ≥ÿßÿ° ÿßŸÑŸÅŸÑ ÿπŸÑŸäŸÉŸÖ Ÿäÿß ÿßÿ≠ŸÑŸâ ÿµÿ≠ÿßÿ® üòç\n",
      "#MohammadAbbas \n",
      "#party #fun #great #time #friends #love #you #all https://t.co/es2ugZBAbz\n",
      "RT @ChristoDoyle: Just for fun I made @goldrushtodd &amp; @goldrush_parker sit inches apart on #TheDirt tonight. Must see @Gold_Rush TV 8/7c @D‚Ä¶\n",
      "RT @BubblyRobinson: donald trump's sons kill (endangered) animals for fun. üê∏‚òïÔ∏è  can y'all make this go viral or https://t.co/oWNTuy4wfz\n",
      "@NewOlderScene great üòÄüòÄ fun to get away!\n",
      "Crazy sexy girls like to have fun. Do you agree? Check this: https://t.co/H2OlT4jicF #tits #bdsm #sextoys #kikgirl https://t.co/viqykptAhZ\n",
      "RT @RonaldoFCabuhat: If iHaveToSpendADay w/ MaiChard, i'll offer myself,listen. We'll talk adult matters,the fun stuffs! #ALDUBMaineEvent h‚Ä¶\n",
      "@MajoRamirezz haha it wasn't as fun as it sounds üòù\n",
      "Finally home from Atlantic City. Fun 2 day vacation but now it's back to the grind\n",
      "RT @JoeyGraceffa: GUYS! Make sure you're sending me a VIDEO question for the Snapchat Q&amp;A! Make them fun! üëªjoeygraceffa16\n",
      "RT @BabyAnimalPics: fun date idea: we go to the animal shelter and adopt every dog\n",
      "RT @gamedestroyer66: Trigger Runners | Side Scrolling Fun: https://t.co/oRzTtmUGlo  #triggerrunners #indiegame #indiedev #GDTV\n",
      "Just taught a kid a lesson. You don't make fun of someone because they have less than you. Your shit can easily be taken from you.\n",
      "Brooklyn Nine-Nine S01E09 Fun #Brooklyn99  https://t.co/fVldkuaACa https://t.co/FbYKPplozK\n",
      "#Zootopia @shakira totally made this movie for me! So much fun. #TryEverything https://t.co/lccWdTAjEi via @YouTube\n",
      "RT @TNutritionista: Had so much fun presenting #guthealth recipes @eatrightnc! Thanks to everyone who attended! #savortheflavor #nnm https:‚Ä¶\n",
      "I liked a @YouTube video from @finfunmermaid https://t.co/42z003OCkb Help Fin Fun Get 40,000 Subscriber Tail giveaway!\n",
      "RT @_AkbarXavier: Show up and have fun courtesy of @blvdetiquettes https://t.co/B7GBY93u5d\n",
      "RT @Peugeot_Hansen: Friday Fun Day - with @SebastienLoeb and @Timmy_Hansen doing what they love. #FastFriday #Peugeot208WRX @FIAWorldRX htt‚Ä¶\n",
      "Via: https://t.co/t8aXirIzWu\n",
      "Young Americans have fun in a boutique https://t.co/qTkcrouUqo\n",
      "@JasonCashe @PerryWallace4CW @CyRiddle @4CWeFed I hope it's make fun of Perry night\n",
      "RT @_FlaDaDepressao: @vascodagama @sportrecife Uma vez inseto, sempre inseto. SEMPRE v√£o viver em fun√ß√£o do Flamengo. Os 2 clubes mais inse‚Ä¶\n",
      "#justona #goodvibes #goodtimes #snooker #chilling #playhard #friends #fun #live #goodfriends‚Ä¶ https://t.co/zvyj1FwosA\n",
      "RT @natekgarner: Unhappiness isnt forever\n",
      "Being made fun of isnt forever\n",
      "Not fitting in isnt forever\n",
      "Suicide is...\n",
      "It's not the answer &amp; im‚Ä¶\n",
      "üòÇ üòÇ üòÇ üòÇ üòÇ üòÇ.   https://t.co/K0wTqalsot\n",
      "RT @ellieweber_: Too much fun @ Roseburg High School https://t.co/oPgPq9wpO0\n",
      "The Week in iOS Apps: Assassin's Creed Identity, Clash Royale, and other new games: Fun and gamesIt‚Äôs the dog ... https://t.co/O6EVuszYQJ\n",
      "\"Make it simple. Make it memorable. Make it inviting to look at. Makenit fun to dead.\" -Leo Burnett\n",
      "The Week in iOS Apps: Assassin's Creed Identity, Clash Royale, and other new games: Fun and gamesIt‚Äôs the dog ... https://t.co/2wieqlcsYC\n",
      "The Week in iOS Apps: Assassin's Creed Identity, Clash Royale, and other new games: Fun and games... https://t.co/2VCOUFzTm8 #Tech #Apple\n",
      "RT @xrzes: Being a vegetarian so fun I just got three bags of broccoli https://t.co/u5XbYNjste\n",
      "RT @miller12_ry: NO LONGER TALKING. EVERYTHING I SAY GETS TAKEN THE WRONG WAY OR GETS MADE FUN OF.\n",
      "Friends,\n",
      "Grab your sweetie and join the Chorale Acadienne singers for a fun evening of entertainment and food... https://t.co/tktKP2o2z4\n"
     ]
    }
   ],
   "source": [
    "for i, tweepy in enumerate(tweets_data):\n",
    "    \n",
    "    print tweepy['text']\n",
    "    \n",
    "    if i == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z =  u'\\U0001f49b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've enjoyed this basketball season though....the journey was sooo fun and exciting while it lasted....üòäüòäüíúüíõ\n"
     ]
    }
   ],
   "source": [
    "print xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz = tweets_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'en'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz['lang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\U0001f3fb'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"I've enjoyed this basketball season though....the journey was sooo fun and exciting while it lasted....\\U0001f60a\\U0001f60a\\U0001f49c\\U0001f49b\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diversity_df = pd.read_csv('data/diversity_table.txt', encoding='utf-8', index_col=0)\n",
    "diversity_df['count'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dd =diversity_df.to_dict()['count'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'\\U0001f483'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dd)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üòä here\n",
      "üíõ here\n",
      "üíú here\n"
     ]
    }
   ],
   "source": [
    "for key in emoji_dict.keys():\n",
    "    if key in xx:\n",
    "        print key, 'here'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tweet Parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import json\n",
    "import nltk\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snowball = SnowballStemmer('english')\n",
    "wordnet = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REGEX = u\"[\\U00002712\\U00002714\\U00002716\\U0000271d\\U00002721\\U00002728\\U00002733\\U00002734\\U00002744\\U00002747\\U0000274c\\U0000274e\\U00002753-\\U00002755\\U00002757\\U00002763\\U00002764\\U00002795-\\U00002797\\U000027a1\\U000027b0\\U000027bf\\U00002934\\U00002935\\U00002b05-\\U00002b07\\U00002b1b\\U00002b1c\\U00002b50\\U00002b55\\U00003030\\U0000303d\\U0001f004\\U0001f0cf\\U0001f170\\U0001f171\\U0001f17e\\U0001f17f\\U0001f18e\\U0001f191-\\U0001f19a\\U0001f201\\U0001f202\\U0001f21a\\U0001f22f\\U0001f232-\\U0001f23a\\U0001f250\\U0001f251\\U0001f300-\\U0001f321\\U0001f324-\\U0001f393\\U0001f396\\U0001f397\\U0001f399-\\U0001f39b\\U0001f39e-\\U0001f3f0\\U0001f3f3-\\U0001f3f5\\U0001f3f7-\\U0001f4fd\\U0001f4ff-\\U0001f53d\\U0001f549-\\U0001f54e\\U0001f550-\\U0001f567\\U0001f56f\\U0001f570\\U0001f573-\\U0001f579\\U0001f587\\U0001f58a-\\U0001f58d\\U0001f590\\U0001f595\\U0001f596\\U0001f5a5\\U0001f5a8\\U0001f5b1\\U0001f5b2\\U0001f5bc\\U0001f5c2-\\U0001f5c4\\U0001f5d1-\\U0001f5d3\\U0001f5dc-\\U0001f5de\\U0001f5e1\\U0001f5e3\\U0001f5ef\\U0001f5f3\\U0001f5fa-\\U0001f64f\\U0001f680-\\U0001f6c5\\U0001f6cb-\\U0001f6d0\\U0001f6e0-\\U0001f6e5\\U0001f6e9\\U0001f6eb\\U0001f6ec\\U0001f6f0\\U0001f6f3\\U0001f910-\\U0001f918\\U0001f980-\\U0001f984\\U0001f9c0\\U00003297\\U00003299\\U000000a9\\U000000ae\\U0000203c\\U00002049\\U00002122\\U00002139\\U00002194-\\U00002199\\U000021a9\\U000021aa\\U0000231a\\U0000231b\\U00002328\\U00002388\\U000023cf\\U000023e9-\\U000023f3\\U000023f8-\\U000023fa\\U000024c2\\U000025aa\\U000025ab\\U000025b6\\U000025c0\\U000025fb-\\U000025fe\\U00002600-\\U00002604\\U0000260e\\U00002611\\U00002614\\U00002615\\U00002618\\U0000261d\\U00002620\\U00002622\\U00002623\\U00002626\\U0000262a\\U0000262e\\U0000262f\\U00002638-\\U0000263a\\U00002648-\\U00002653\\U00002660\\U00002663\\U00002665\\U00002666\\U00002668\\U0000267b\\U0000267f\\U00002692-\\U00002694\\U00002696\\U00002697\\U00002699\\U0000269b\\U0000269c\\U000026a0\\U000026a1\\U000026aa\\U000026ab\\U000026b0\\U000026b1\\U000026bd\\U000026be\\U000026c4\\U000026c5\\U000026c8\\U000026ce\\U000026cf\\U000026d1\\U000026d3\\U000026d4\\U000026e9\\U000026ea\\U000026f0-\\U000026f5\\U000026f7-\\U000026fa\\U000026fd\\U00002702\\U00002705\\U00002708-\\U0000270d\\U0000270f]|[#]\\U000020e3|[*]\\U000020e3|[0]\\U000020e3|[1]\\U000020e3|[2]\\U000020e3|[3]\\U000020e3|[4]\\U000020e3|[5]\\U000020e3|[6]\\U000020e3|[7]\\U000020e3|[8]\\U000020e3|[9]\\U000020e3|\\U0001f1e6[\\U0001f1e8-\\U0001f1ec\\U0001f1ee\\U0001f1f1\\U0001f1f2\\U0001f1f4\\U0001f1f6-\\U0001f1fa\\U0001f1fc\\U0001f1fd\\U0001f1ff]|\\U0001f1e7[\\U0001f1e6\\U0001f1e7\\U0001f1e9-\\U0001f1ef\\U0001f1f1-\\U0001f1f4\\U0001f1f6-\\U0001f1f9\\U0001f1fb\\U0001f1fc\\U0001f1fe\\U0001f1ff]|\\U0001f1e8[\\U0001f1e6\\U0001f1e8\\U0001f1e9\\U0001f1eb-\\U0001f1ee\\U0001f1f0-\\U0001f1f5\\U0001f1f7\\U0001f1fa-\\U0001f1ff]|\\U0001f1e9[\\U0001f1ea\\U0001f1ec\\U0001f1ef\\U0001f1f0\\U0001f1f2\\U0001f1f4\\U0001f1ff]|\\U0001f1ea[\\U0001f1e6\\U0001f1e8\\U0001f1ea\\U0001f1ec\\U0001f1ed\\U0001f1f7-\\U0001f1fa]|\\U0001f1eb[\\U0001f1ee-\\U0001f1f0\\U0001f1f2\\U0001f1f4\\U0001f1f7]|\\U0001f1ec[\\U0001f1e6\\U0001f1e7\\U0001f1e9-\\U0001f1ee\\U0001f1f1-\\U0001f1f3\\U0001f1f5-\\U0001f1fa\\U0001f1fc\\U0001f1fe]|\\U0001f1ed[\\U0001f1f0\\U0001f1f2\\U0001f1f3\\U0001f1f7\\U0001f1f9\\U0001f1fa]|\\U0001f1ee[\\U0001f1e8-\\U0001f1ea\\U0001f1f1-\\U0001f1f4\\U0001f1f6-\\U0001f1f9]|\\U0001f1ef[\\U0001f1ea\\U0001f1f2\\U0001f1f4\\U0001f1f5]|\\U0001f1f0[\\U0001f1ea\\U0001f1ec-\\U0001f1ee\\U0001f1f2\\U0001f1f3\\U0001f1f5\\U0001f1f7\\U0001f1fc\\U0001f1fe\\U0001f1ff]|\\U0001f1f1[\\U0001f1e6-\\U0001f1e8\\U0001f1ee\\U0001f1f0\\U0001f1f7-\\U0001f1fb\\U0001f1fe]|\\U0001f1f2[\\U0001f1e6\\U0001f1e8-\\U0001f1ed\\U0001f1f0-\\U0001f1ff]|\\U0001f1f3[\\U0001f1e6\\U0001f1e8\\U0001f1ea-\\U0001f1ec\\U0001f1ee\\U0001f1f1\\U0001f1f4\\U0001f1f5\\U0001f1f7\\U0001f1fa\\U0001f1ff]|\\U0001f1f4\\U0001f1f2|\\U0001f1f5[\\U0001f1e6\\U0001f1ea-\\U0001f1ed\\U0001f1f0-\\U0001f1f3\\U0001f1f7-\\U0001f1f9\\U0001f1fc\\U0001f1fe]|\\U0001f1f6\\U0001f1e6|\\U0001f1f7[\\U0001f1ea\\U0001f1f4\\U0001f1f8\\U0001f1fa\\U0001f1fc]|\\U0001f1f8[\\U0001f1e6-\\U0001f1ea\\U0001f1ec-\\U0001f1f4\\U0001f1f7-\\U0001f1f9\\U0001f1fb\\U0001f1fd-\\U0001f1ff]|\\U0001f1f9[\\U0001f1e6\\U0001f1e8\\U0001f1e9\\U0001f1eb-\\U0001f1ed\\U0001f1ef-\\U0001f1f4\\U0001f1f7\\U0001f1f9\\U0001f1fb\\U0001f1fc\\U0001f1ff]|\\U0001f1fa[\\U0001f1e6\\U0001f1ec\\U0001f1f2\\U0001f1f8\\U0001f1fe\\U0001f1ff]|\\U0001f1fb[\\U0001f1e6\\U0001f1e8\\U0001f1ea\\U0001f1ec\\U0001f1ee\\U0001f1f3\\U0001f1fa]|\\U0001f1fc[\\U0001f1eb\\U0001f1f8]|\\U0001f1fd\\U0001f1f0|\\U0001f1fe[\\U0001f1ea\\U0001f1f9]|\\U0001f1ff[\\U0001f1e6\\U0001f1f2\\U0001f1fc]|[0-9*#]\\ufe0f\\u20e3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tweet_process(tweet):\n",
    "    KEY = 'text'\n",
    "    try:\n",
    "        tw = json.loads(tweet.strip())\n",
    "        if KEY not in tw or tw['lang']!= 'en':\n",
    "            return None\n",
    "        return tw\n",
    "\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def emoji_preprocess(tweet, predict=False):\n",
    "    # add space before and after space\n",
    "    for emoji in re.findall(REGEX, tweet):\n",
    "        tweet = tweet.replace(emoji, ' ' + emoji + ' ')\n",
    "\n",
    "    # tokenize and remove rt and @ and https://\n",
    "    tweet = re.sub('\\?', '', tweet)\n",
    "    tweet = re.sub('\\.', '', tweet)\n",
    "    tweet = re.sub(',', '', tweet)\n",
    "    tweet = re.sub('!', '', tweet)\n",
    "\n",
    "    tweet_tmp = [ snowball.stem(wd) for wd in tweet.strip('rt').split() if not wd.startswith('@') and not wd.startswith('http') and not wd.startswith('#') ]\n",
    "\n",
    "    if predict:\n",
    "        tweet_token = ['<s>'] + tweet_tmp\n",
    "    else:\n",
    "        tweet_token = ['<s>'] + tweet_tmp + ['</s>']\n",
    "\n",
    "    return tweet_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigrams(tweet):\n",
    "    return [ ((w1,), w2) for w1, w2 in nltk.bigrams(tweet)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigram_dict((((w1, w2), w_f), cnt)): \n",
    "    global bigram_dict\n",
    "    bigram_dict[(w1,w2)][w_f] = cnt\n",
    "    return 'cool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigrams(tweet):\n",
    "    # generate trigrams from tweets\n",
    "    return [((w1, w2), w3) for w1, w2, w3 in nltk.trigrams(tweet)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quadgrams(tweet):\n",
    "    #generate n grams\n",
    "    return [((w1, w2, w3), w4) for w1, w2, w3, w4 in nltk.ngrams(tweet, 4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets =  sc.textFile('data/twitter_dump_small.txt')\\\n",
    ".filter(lambda tw: len(tw)>1)\\\n",
    ".filter(lambda tw: 'created_at' in tw)\\\n",
    ".map(tweet_process)\\\n",
    ".filter(lambda tw: tw != None)\\\n",
    ".map(lambda tw: tw['text'].lower() )\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_tokens = tweets.map(emoji_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_count = tweets.map(emoji_preprocess).flatMap(bigrams).map(lambda bg: (bg, 1)).reduceByKey(lambda cnt1, cnt2: cnt1+cnt2).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_count = tweets.map(emoji_preprocess).flatMap(trigrams).map(lambda bg: (bg, 1)).reduceByKey(lambda cnt1, cnt2: cnt1+cnt2).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quadgrams_count = tweets.map(emoji_preprocess).flatMap(quadgrams).map(lambda bg: (bg, 1)).reduceByKey(lambda cnt1, cnt2: cnt1+cnt2).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_dict = defaultdict(Counter)\n",
    "trigram_dict = defaultdict(Counter)\n",
    "quadgram_dict= defaultdict(Counter) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (((w0,),w1) , cnt) in bigram_count:\n",
    "    bigram_dict[w0][w1] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for (((w0, w1), w2), cnt) in trigram_count:\n",
    "    trigram_dict[(w0, w1)][w2] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for (((w0, w1, w2), w3), cnt) in quadgrams_count:\n",
    "    quadgram_dict[(w0, w1, w2)][w3] = cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'luck', 6),\n",
       " (u'girl', 4),\n",
       " (u'and', 2),\n",
       " (u'rt', 2),\n",
       " (u'screenplay', 2),\n",
       " (u'work', 2),\n",
       " (u'practic', 2),\n",
       " (u'movi', 2),\n",
       " (u'show', 2),\n",
       " (u'hang', 2),\n",
       " (u'game', 2),\n",
       " (u'job', 2),\n",
       " (u'mom', 2),\n",
       " (u'time', 2),\n",
       " (u'news', 2),\n",
       " (u'on', 2),\n",
       " ('</s>', 2),\n",
       " (u'truli', 2)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_dict[u'good'].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proc_str = emoji_preprocess('how are you', predict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'guy'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(proc_str[-2:]) in trigram_dict\n",
    "trigram_dict[tuple(proc_str[-2:])].most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'oh', 2)]\n"
     ]
    }
   ],
   "source": [
    "if tuple(proc_str[-3:]) in quadgram_dict:\n",
    "    print quadgram_dict[tuple(proc_str[-3:])].most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'oh'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quadgram_dict[tuple(proc_str[-3:])].most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zz = defaultdict(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz['test']['tt']= 3\n",
    "zz['test']['xx']= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zz['tests'].most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count num tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588343"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile('/home/han/Documents/Github/emoji_predictor/data/twitter_dump.txt').filter(lambda x: len(x)>1 and 'created_at' in x).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'[\\u2712\\u2714\\u2716\\u271d\\u2721\\u2728\\u2733\\u2734\\u2744\\u2747\\u274c\\u274e\\u2753-\\u2755\\u2757\\u2763\\u2764\\u2795-\\u2797\\u27a1\\u27b0\\u27bf\\u2934\\u2935\\u2b05-\\u2b07\\u2b1b\\u2b1c\\u2b50\\u2b55\\u3030\\u303d\\U0001f004\\U0001f0cf\\U0001f170\\U0001f171\\U0001f17e\\U0001f17f\\U0001f18e\\U0001f191-\\U0001f19a\\U0001f201\\U0001f202\\U0001f21a\\U0001f22f\\U0001f232-\\U0001f23a\\U0001f250\\U0001f251\\U0001f300-\\U0001f321\\U0001f324-\\U0001f393\\U0001f396\\U0001f397\\U0001f399-\\U0001f39b\\U0001f39e-\\U0001f3f0\\U0001f3f3-\\U0001f3f5\\U0001f3f7-\\U0001f4fd\\U0001f4ff-\\U0001f53d\\U0001f549-\\U0001f54e\\U0001f550-\\U0001f567\\U0001f56f\\U0001f570\\U0001f573-\\U0001f579\\U0001f587\\U0001f58a-\\U0001f58d\\U0001f590\\U0001f595\\U0001f596\\U0001f5a5\\U0001f5a8\\U0001f5b1\\U0001f5b2\\U0001f5bc\\U0001f5c2-\\U0001f5c4\\U0001f5d1-\\U0001f5d3\\U0001f5dc-\\U0001f5de\\U0001f5e1\\U0001f5e3\\U0001f5ef\\U0001f5f3\\U0001f5fa-\\U0001f64f\\U0001f680-\\U0001f6c5\\U0001f6cb-\\U0001f6d0\\U0001f6e0-\\U0001f6e5\\U0001f6e9\\U0001f6eb\\U0001f6ec\\U0001f6f0\\U0001f6f3\\U0001f910-\\U0001f918\\U0001f980-\\U0001f984\\U0001f9c0\\u3297\\u3299\\xa9\\xae\\u203c\\u2049\\u2122\\u2139\\u2194-\\u2199\\u21a9\\u21aa\\u231a\\u231b\\u2328\\u2388\\u23cf\\u23e9-\\u23f3\\u23f8-\\u23fa\\u24c2\\u25aa\\u25ab\\u25b6\\u25c0\\u25fb-\\u25fe\\u2600-\\u2604\\u260e\\u2611\\u2614\\u2615\\u2618\\u261d\\u2620\\u2622\\u2623\\u2626\\u262a\\u262e\\u262f\\u2638-\\u263a\\u2648-\\u2653\\u2660\\u2663\\u2665\\u2666\\u2668\\u267b\\u267f\\u2692-\\u2694\\u2696\\u2697\\u2699\\u269b\\u269c\\u26a0\\u26a1\\u26aa\\u26ab\\u26b0\\u26b1\\u26bd\\u26be\\u26c4\\u26c5\\u26c8\\u26ce\\u26cf\\u26d1\\u26d3\\u26d4\\u26e9\\u26ea\\u26f0-\\u26f5\\u26f7-\\u26fa\\u26fd\\u2702\\u2705\\u2708-\\u270d\\u270f]|[#]\\u20e3|[*]\\u20e3|[0]\\u20e3|[1]\\u20e3|[2]\\u20e3|[3]\\u20e3|[4]\\u20e3|[5]\\u20e3|[6]\\u20e3|[7]\\u20e3|[8]\\u20e3|[9]\\u20e3|\\U0001f1e6[\\U0001f1e8-\\U0001f1ec\\U0001f1ee\\U0001f1f1\\U0001f1f2\\U0001f1f4\\U0001f1f6-\\U0001f1fa\\U0001f1fc\\U0001f1fd\\U0001f1ff]|\\U0001f1e7[\\U0001f1e6\\U0001f1e7\\U0001f1e9-\\U0001f1ef\\U0001f1f1-\\U0001f1f4\\U0001f1f6-\\U0001f1f9\\U0001f1fb\\U0001f1fc\\U0001f1fe\\U0001f1ff]|\\U0001f1e8[\\U0001f1e6\\U0001f1e8\\U0001f1e9\\U0001f1eb-\\U0001f1ee\\U0001f1f0-\\U0001f1f5\\U0001f1f7\\U0001f1fa-\\U0001f1ff]|\\U0001f1e9[\\U0001f1ea\\U0001f1ec\\U0001f1ef\\U0001f1f0\\U0001f1f2\\U0001f1f4\\U0001f1ff]|\\U0001f1ea[\\U0001f1e6\\U0001f1e8\\U0001f1ea\\U0001f1ec\\U0001f1ed\\U0001f1f7-\\U0001f1fa]|\\U0001f1eb[\\U0001f1ee-\\U0001f1f0\\U0001f1f2\\U0001f1f4\\U0001f1f7]|\\U0001f1ec[\\U0001f1e6\\U0001f1e7\\U0001f1e9-\\U0001f1ee\\U0001f1f1-\\U0001f1f3\\U0001f1f5-\\U0001f1fa\\U0001f1fc\\U0001f1fe]|\\U0001f1ed[\\U0001f1f0\\U0001f1f2\\U0001f1f3\\U0001f1f7\\U0001f1f9\\U0001f1fa]|\\U0001f1ee[\\U0001f1e8-\\U0001f1ea\\U0001f1f1-\\U0001f1f4\\U0001f1f6-\\U0001f1f9]|\\U0001f1ef[\\U0001f1ea\\U0001f1f2\\U0001f1f4\\U0001f1f5]|\\U0001f1f0[\\U0001f1ea\\U0001f1ec-\\U0001f1ee\\U0001f1f2\\U0001f1f3\\U0001f1f5\\U0001f1f7\\U0001f1fc\\U0001f1fe\\U0001f1ff]|\\U0001f1f1[\\U0001f1e6-\\U0001f1e8\\U0001f1ee\\U0001f1f0\\U0001f1f7-\\U0001f1fb\\U0001f1fe]|\\U0001f1f2[\\U0001f1e6\\U0001f1e8-\\U0001f1ed\\U0001f1f0-\\U0001f1ff]|\\U0001f1f3[\\U0001f1e6\\U0001f1e8\\U0001f1ea-\\U0001f1ec\\U0001f1ee\\U0001f1f1\\U0001f1f4\\U0001f1f5\\U0001f1f7\\U0001f1fa\\U0001f1ff]|\\U0001f1f4\\U0001f1f2|\\U0001f1f5[\\U0001f1e6\\U0001f1ea-\\U0001f1ed\\U0001f1f0-\\U0001f1f3\\U0001f1f7-\\U0001f1f9\\U0001f1fc\\U0001f1fe]|\\U0001f1f6\\U0001f1e6|\\U0001f1f7[\\U0001f1ea\\U0001f1f4\\U0001f1f8\\U0001f1fa\\U0001f1fc]|\\U0001f1f8[\\U0001f1e6-\\U0001f1ea\\U0001f1ec-\\U0001f1f4\\U0001f1f7-\\U0001f1f9\\U0001f1fb\\U0001f1fd-\\U0001f1ff]|\\U0001f1f9[\\U0001f1e6\\U0001f1e8\\U0001f1e9\\U0001f1eb-\\U0001f1ed\\U0001f1ef-\\U0001f1f4\\U0001f1f7\\U0001f1f9\\U0001f1fb\\U0001f1fc\\U0001f1ff]|\\U0001f1fa[\\U0001f1e6\\U0001f1ec\\U0001f1f2\\U0001f1f8\\U0001f1fe\\U0001f1ff]|\\U0001f1fb[\\U0001f1e6\\U0001f1e8\\U0001f1ea\\U0001f1ec\\U0001f1ee\\U0001f1f3\\U0001f1fa]|\\U0001f1fc[\\U0001f1eb\\U0001f1f8]|\\U0001f1fd\\U0001f1f0|\\U0001f1fe[\\U0001f1ea\\U0001f1f9]|\\U0001f1ff[\\U0001f1e6\\U0001f1f2\\U0001f1fc]|[0-9*#]\\ufe0f\\u20e3'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Testing word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/home/han/.api_key/awsaccesskey.json') as f:\n",
    "    key= json.load(f)\n",
    "    \n",
    "    access= key['access-key']\n",
    "    secret = key['secret-access-key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile('s3n://'+access+':'+secret +'@sparkdatasets/text8_lines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.feature import Word2Vec\n",
    "word2vec = Word2Vec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2v = word2vec.fit(tweets_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíñ\n"
     ]
    }
   ],
   "source": [
    "print w2v.findSynonyms('you',10)[5][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üáΩ\n"
     ]
    }
   ],
   "source": [
    "print u'\\U0001f1fd'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# boto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import boto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3Connection:s3.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "conn = boto.connect_s3()\n",
    "print conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bucket: han.indiv.bucket>,\n",
       " <Bucket: han.indiv.bucket2>,\n",
       " <Bucket: han.mapreduce>,\n",
       " <Bucket: han.tweets.08>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.get_all_buckets()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ssl\n",
    "if hasattr(ssl, '_create_unverified_context'):\n",
    "   ssl._create_default_https_context = ssl._create_unverified_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = conn.get_bucket('han.tweets.08')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = b.new_key('tweets.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d9378c60ce57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_contents_from_filename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'archiveteam-twitter-stream-2015-08.tar'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'public-read'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mset_contents_from_filename\u001b[1;34m(self, filename, headers, replace, cb, num_cb, policy, md5, reduced_redundancy, encrypt_key)\u001b[0m\n\u001b[0;32m   1360\u001b[0m                                                \u001b[0mnum_cb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m                                                \u001b[0mreduced_redundancy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1362\u001b[1;33m                                                encrypt_key=encrypt_key)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     def set_contents_from_string(self, string_data, headers=None, replace=True,\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mset_contents_from_file\u001b[1;34m(self, fp, headers, replace, cb, num_cb, policy, md5, reduced_redundancy, query_args, encrypt_key, size, rewind)\u001b[0m\n\u001b[0;32m   1267\u001b[0m                     \u001b[1;31m# compute_md5() and also set self.size to actual\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m                     \u001b[1;31m# size of the bytes read computing the md5.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1269\u001b[1;33m                     \u001b[0mmd5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_md5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1270\u001b[0m                     \u001b[1;31m# adjust size if required\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m                     \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/boto/s3/key.pyc\u001b[0m in \u001b[0;36mcompute_md5\u001b[1;34m(self, fp, size)\u001b[0m\n\u001b[0;32m   1018\u001b[0m             \u001b[1;32min\u001b[0m \u001b[0mplace\u001b[0m \u001b[0minto\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mparts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mLess\u001b[0m \u001b[0mbytes\u001b[0m \u001b[0mmay\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mavailable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \"\"\"\n\u001b[1;32m-> 1020\u001b[1;33m         \u001b[0mhex_digest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb64_digest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_md5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m         \u001b[1;31m# Returned values are MD5 hash, base64 encoded MD5 hash, and data size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[1;31m# The internal implementation of compute_md5() needs to return the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/boto/utils.pyc\u001b[0m in \u001b[0;36mcompute_md5\u001b[1;34m(fp, buf_size, size)\u001b[0m\n\u001b[0;32m    989\u001b[0m              \u001b[0mthe\u001b[0m \u001b[0mthird\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    990\u001b[0m     \"\"\"\n\u001b[1;32m--> 991\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcompute_hash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_algorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/boto/utils.pyc\u001b[0m in \u001b[0;36mcompute_hash\u001b[1;34m(fp, buf_size, size, hash_algorithm)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m         \u001b[0mhash_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tweets.set_contents_from_filename('archiveteam-twitter-stream-2015-08.tar', policy='public-read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zz = sc.textFile('/home/han/Documents/Galvanize_data_science/project/Data/00.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 6, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1293, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-12-6f7edcdc0604>\", line 1, in <lambda>\nTypeError: file() argument 1 must be encoded string without NULL bytes, not unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:393)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1293, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-12-6f7edcdc0604>\", line 1, in <lambda>\nTypeError: file() argument 1 must be encoded string without NULL bytes, not unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6f7edcdc0604>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mzz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbz2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/usr/local/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mfirst\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m         \"\"\"\n\u001b[1;32m-> 1315\u001b[1;33m         \u001b[0mrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m   1295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             \u001b[0mitems\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/spark/python/pyspark/context.pyc\u001b[0m in \u001b[0;36mrunJob\u001b[1;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[1;31m# SparkContext#runJob.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         \u001b[0mport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/py4j/java_gateway.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    833\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m         return_value = get_return_value(\n\u001b[1;32m--> 835\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/han/anaconda2/lib/python2.7/site-packages/py4j/protocol.pyc\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    308\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    309\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    311\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 6, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1293, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-12-6f7edcdc0604>\", line 1, in <lambda>\nTypeError: file() argument 1 must be encoded string without NULL bytes, not unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\tat java.lang.Thread.run(Thread.java:745)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:799)\n\tat scala.Option.foreach(Option.scala:236)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:799)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1640)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:393)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:497)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:745)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 111, in main\n    process()\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 106, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 263, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/spark/python/pyspark/rdd.py\", line 1293, in takeUpToNumLeft\n    yield next(iterator)\n  File \"<ipython-input-12-6f7edcdc0604>\", line 1, in <lambda>\nTypeError: file() argument 1 must be encoded string without NULL bytes, not unicode\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:207)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:125)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:70)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:270)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:89)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "zz.map(lambda x: bz2.BZ2File(x)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = bz2.BZ2File('/home/han/Documents/Galvanize_data_science/project/Data/00/30.json.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hmmm 20 minutes until boarding... I'm gonna let my phone get to 95% and then bathroom and then *waiting anxiously to board*\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(test.readline().strip())['text'].encode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\u3055\\u3066\\u3001\\u8089\\u3068\\u5fc3\\u3092\\u901a\\u308f\\u305b\\u308b\\u304b\n"
     ]
    }
   ],
   "source": [
    "print u\"\\\\u3055\\\\u3066\\\\u3001\\\\u8089\\\\u3068\\\\u5fc3\\\\u3092\\\\u901a\\\\u308f\\\\u305b\\\\u308b\\\\u304b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
